{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import mxnet as mx\n",
    "mnist = mx.test_utils.get_mnist()\n",
    "\n",
    "# Fix the seed\n",
    "mx.random.seed(42)\n",
    "\n",
    "# Set the compute context, GPU is available otherwise CPU\n",
    "ctx = mx.gpu() if mx.context.num_gpus() else mx.cpu()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "batch_size = 100\n",
    "train_iter = mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multilayer Perceptron"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "data = mx.sym.var('data')\n",
    "# Flatten the data from 4-D shape into 2-D (batch_size, num_channel*width*height)\n",
    "data = mx.sym.flatten(data=data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# The first fully-connected layer and the corresponding activation function\n",
    "fc1  = mx.sym.FullyConnected(data=data, num_hidden=128)\n",
    "act1 = mx.sym.Activation(data=fc1, act_type=\"relu\")\n",
    "\n",
    "# The second fully-connected layer and the corresponding activation function\n",
    "fc2  = mx.sym.FullyConnected(data=act1, num_hidden = 64)\n",
    "act2 = mx.sym.Activation(data=fc2, act_type=\"relu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# MNIST has 10 classes\n",
    "fc3  = mx.sym.FullyConnected(data=act2, num_hidden=10)\n",
    "# Softmax with cross entropy loss\n",
    "mlp  = mx.sym.SoftmaxOutput(data=fc3, name='softmax')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)  # logging to stdout\n",
    "# create a trainable module on compute context\n",
    "mlp_model = mx.mod.Module(symbol=mlp, context=ctx)\n",
    "mlp_model.fit(train_iter,  # train data\n",
    "              eval_data=val_iter,  # validation data\n",
    "              optimizer='sgd',  # use SGD to train\n",
    "              optimizer_params={'learning_rate':0.1},  # use fixed learning rate\n",
    "              eval_metric='acc',  # report accuracy during training\n",
    "              batch_end_callback = mx.callback.Speedometer(batch_size, 100), # output progress for each 100 data batches\n",
    "              num_epoch=10)  # train for at most 10 dataset passes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prediction\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], None, batch_size)\n",
    "prob = mlp_model.predict(test_iter)\n",
    "assert prob.shape == (10000, 10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)\n",
    "# predict accuracy of mlp\n",
    "acc = mx.metric.Accuracy()\n",
    "mlp_model.score(test_iter, acc)\n",
    "print(acc)\n",
    "assert acc.get()[1] > 0.96, \"Achieved accuracy (%f) is lower than expected (0.96)\" % acc.get()[1]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "EvalMetric: {'accuracy': 0.9675}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolutional Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "data = mx.sym.var('data')\n",
    "# first conv layer\n",
    "conv1 = mx.sym.Convolution(data=data, kernel=(5,5), num_filter=20)\n",
    "tanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\n",
    "pool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# second conv layer\n",
    "conv2 = mx.sym.Convolution(data=pool1, kernel=(5,5), num_filter=50)\n",
    "tanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\n",
    "pool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# first fullc layer\n",
    "flatten = mx.sym.flatten(data=pool2)\n",
    "fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "tanh3 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n",
    "# second fullc\n",
    "fc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=10)\n",
    "# softmax loss\n",
    "lenet = mx.sym.SoftmaxOutput(data=fc2, name='softmax')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "lenet_model = mx.mod.Module(symbol=lenet, context=ctx)\n",
    "# train with the same\n",
    "lenet_model.fit(train_iter,\n",
    "                eval_data=val_iter,\n",
    "                optimizer='sgd',\n",
    "                optimizer_params={'learning_rate':0.1},\n",
    "                eval_metric='acc',\n",
    "                batch_end_callback = mx.callback.Speedometer(batch_size, 100),\n",
    "                num_epoch=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[22:40:05] ../src/executor/graph_executor.cc:1995: Subgraph backend MKLDNN is activated.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], None, batch_size)\n",
    "prob = lenet_model.predict(test_iter)\n",
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)\n",
    "# predict accuracy for lenet\n",
    "acc = mx.metric.Accuracy()\n",
    "lenet_model.score(test_iter, acc)\n",
    "print(acc)\n",
    "assert acc.get()[1] > 0.98, \"Achieved accuracy (%f) is lower than expected (0.98)\" % acc.get()[1]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "EvalMetric: {'accuracy': 0.9871}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}